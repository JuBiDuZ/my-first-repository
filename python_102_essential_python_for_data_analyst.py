# -*- coding: utf-8 -*-
"""Essential Python for Data Analyst.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pheDSoFMhQg1OqHlB9S9PRsXqHIEj9P3

#Essential Python for Data Analyst

- csv
- csv monster
- json
- pandas / numpy
- requests and API
- gazpacho simple web scraping
- sklearn basic template

## CSV
"""

import csv

file = open("My_data/hotel.csv")

data = csv.reader(file)
file.close

# context manager (with)
import csv
result = []

with open("My_data/hotel.csv", "r") as file: # "r" -> read
    data = csv.reader(file)
    for row in data:
        result.append(row)

print(result)

# try except
import csv
result = []

try:
    with open("My_data/hotel.csv", "r") as file: # "r" -> read
        data = csv.reader(file)
        for row in data:
            result.append(row)
    print("Load data successfully.")
except:
    print("File not found.")
    
print(result)

result

with open("output/student.csv", "w") as file: #w -> write
    writer = csv.writer(file)
    writer.writerow(["id", "name"]) # รับ input เป็น List
    writer.writerow([1, "Boss"])
    writer.writerow([2, "Toy"])
    writer.writerow([3, "TK"])

!cat output/student.csv

# write multiple row
with open("output/all_student.csv", "w") as file: #w -> write
    writer = csv.writer(file)
    writer.writerow(["id", "name"]) # รับ input เป็น List
    writer.writerows([[1, "Boss"], [2, "Toy"], [3, "TK"]])

"""## JSON

JSON = JavaScript Object Notation

- JSON == dictionary
"""

customer = {
    "name" : "kevin",
    "age" : 25,
    "school" : "DataRockie",
    "movies" : ["Thor", "Batman"]
}
customer

customer["movies"][0]

# Add new row (assign new key)
customer["skill"] = ["SQL", "R", "Python"]

customer

# remove row (remove key)
del customer["name"]

import json

# write json file
with open("output/customer.json", "w") as file:
    json.dump(customer, file)

!ls output

!cat output/customer.json

# read json file
with open("output/customer.json") as file:
    dd = json.load(file)

print(dd)

!dir output

"""## CSV Monster class"""

class CSVMonster:
    def __init__(self):
        self.list_data = []
    
    def read_csv(self, file_name):
        try:
            with open(file_name, "r") as file:
                data = csv.reader(file)
                for row in data:
                    self.list_data.append(row)
            print("Load data successfully.")
        except:
            print("Please check filename again.")
    
    def head(self, n=5):
        header = self.list_data[0]
        rows = self.list_data[1:n+1]
        print(header)
        for row in rows:
            print(row)

    def tail(self, n=5):
        header = self.list_data[0]
        rows = self.list_data[-n:]
        print(header)
        for row in rows:
            print(row)

    def filter_city(self, city):
        result = []
        for row in self.list_data:
            if row[2] == city:
                result.append(row)
        for row in result:
            print(row)

    def find_avg_price(self):
        prices = []
        for row in self.list_data[1:]:
            prices.append( int(row[3]) )
        avg_price = sum(prices) / len(prices)
        print(f"Average price per night: {avg_price} USD.")

monster = CSVMonster()
monster.read_csv("my_data/hotel.csv")

monster.list_data

"""## การบ้าน ค้อน กรรไกร กระดาษ

- ใช้ import random เพื่อสร้าง module random
- หากต้องการ loop ต้องให้ทั้งค่าที่ computer random และ player choose อยู่ใน while ด้วย ไม่ง้นจะไม่มีที่ลูป
- random.choice เป็นคำสั่งที่ใช้ในการ random
"""

import random

rsp_list = ["rock", "scissors", "paper"]

def game():

    while True:
        computer_choose = random.choice(rsp_list) #หากย้าย line นี้ไปนอก while True ค่าจะ random แค่รอบเดียว
        player_choose = input("Choose your rock, scissors or paper : ") #หากย้าย line นี้ไปนอก while True ค่าจะวนลูปไม่มีจบ
        if player_choose == computer_choose:
            print("Tie! Please try again")
        elif player_choose == "rock" and computer_choose == "scissors":
            print("You win")
            break
        elif player_choose == "paper" and computer_choose == "rock":
            print("You win")
            break
        elif player_choose == "scissors" and computer_choose == "paper":
            print("You win")
            break
        else:
            print("You lose, Pease Try again")

game()

"""## Project ATM with OOP"""

balance = 0
class ATM:
    def __init__(self, name):
        self.name = name

    def depo(self):
        depo_input = input("How much do you want to depisit : ")
        print(f"You balance is {balance + int(depo_input)}")
        balance = balance + int(depo_input)

atm = ATM("Boss")
atm.depo()

"""# Into to Pandas / Numpy"""

# create data frame from scratch
import pandas as pd
import numpy as np

# dictionary
customers = {
    "name" : ["Toy", "anna", "mary", "david"],
    "age" : [32, 25, 20, 28]
}

df = pd.DataFrame(customers) #import function pandas มาแล้ว ก็เรียกใช้ function ของ pandas ได้เลย
print(df)
print(type(df))

# read csv file
store = pd.read_csv("my_data/Sample SuperStore.csv")

# preview first five rows
store.head(5)

# previrew last rows
store.tail(2)

# see df information
store.info() # object  -> string

# shape attribute
store.shape # attribute != method ไม่ต้องมีวงเล็บ
# 9994 rows , 21 columns

# column names
store.columns
list(store.columns) # แปลงให้เป็น list

# Clean columns names
# 1. make it lower case
# 2. replace " " with "_"
col_names = list(store.columns)

clean_col_name = []

for name in col_names:
    temp = name.lower().replace(" ", "_").replace("-", "_")
    clean_col_name.append(temp)

print(clean_col_name)

# list comprehension
clean_name = [name.lower().replace(" ", "_").replace("-", "_") for name in col_names]
print(clean_name)

# assign clean_names back to store df
store.columns = clean_name # แทนที่ col name เก่าด้วย clean col name 
store.head(2)

# missing values
store.isna().sum()

# select columns
# single column
store['product_name']
# multi columns
store[['product_name', 'sales', 'profit']] # เอา list มาครอลบอีกทีนึง

# filter rows
# .query()
high_sales = store.query("sales > 900")[["customer_name", "segment", "sales"]]
high_sales.head()

# count unique item
store['segment'].value_counts()

# filter multiple conditions
df1 = store.query("segment == 'Consumer' and sales > 500 ")[["segment", "sales"]]
df1.head()

# group by + aggregate
store.groupby("state")["sales"].sum() # gropu by states -> sum sales

# group by multiple columns and multiple arrgegate (use list)
store.groupby(["state", "segment"])[["sales", "profit", "quantity"]].sum()

# mulitple aggregate function
result = store.groupby(["state", "segment"])[["sales", "profit", "quantity"]]\
    .agg(['mean', 'sum', 'min', 'max', 'std'])\
    .reset_index() # reset index ใส่เพื่อให้อ่านง่าย export ออกมาแล้วสวยงาม

# export csv
result.to_csv("output/sales_by_state.csv")

"""## Numpy

Numerical Python

- ใช้หาค่าสถิติ
- ใช้ทำ matrix
"""

numbers = [1, 5, 9, 12]

numbers + numbers

arr_numbers = np.array(numbers)
print(arr_numbers, type(arr_numbers))

arr_numbers + arr_numbers

# statistics
arr_numbers.mean()
arr_numbers.sum()

print(np.median(arr_numbers))
print(np.mean(arr_numbers))
print(np.sum(arr_numbers))
print(np.std(arr_numbers))
print(np.min(arr_numbers))
print(np.max(arr_numbers))

# metrix (2d array)
a = np.array([ [1, 2] , [3, 4] ])
print(a)

a * 2

# dot notation
b = np.array([ [5,0], [1,2] ])
print(a,"\n\n" , b)

a * b # เป็นการคุณ matrix ที่ผิดวิธื

a.dot(b) # คูณ matrix ที่ถูกต้อง

"""## Gazpacho"""

# gazpacho
# install
!pip install gazpacho

!pip list | grep ^gaz

# import function/ module
from gazpacho import Soup
import requests

# 1. have url
# 2. get request that url
# 3. parsing HTML data
# 4. find HTML element that you want

url = "https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc"

response = requests.get(url) # request response cycle ส่ง request ไปที่ url แล้ว url จะ response กลับมา
response.status_code # 200 แสดงว่า รันสำเร็จ

imdb = Soup(response.text)

type(imdb)

# get title name
result = imdb.find("h3", {'class' : 'lister-item-header'})
titles = []
for title in result:
    titles.append(title.strip())
print(titles)
# h3 คือตำแหน่งที่เราต้องการจะหา , class เป็นการ filter ชื่อที่ประกอบไปด้วยคำว่า lister-item-header
# strip คือการ cut ให้เหลือแต่ string จึงได้มาเฉพาะชื่อหนัง

# สามารถเขียนแบบย่อได้ดังนี้ (list comperhension)
# result = imdb.find("h3", {'class': 'lister-item-header'})
# titles = [title.strip() for title in result]
# print(titles)

# get moive runtime
runtimes = []
result2 = imdb.find("span", {'class' : 'runtime'})
for runtime in result2:
    runtimes.append(int(runtime.strip().replace(" min", "")))
print(runtimes)

# สามารถเขียนแบบย่อได้ดังนี้ (list comperhension)
# result2 = imdb.find("span", {"class": "runtime"})
# runtimes = [int(runtime.strip().replace(" min", "")) for runtime in result2 ]
# print(runtimes)

# dataframe
data = {
    "title" : titles,
    "runtime" : runtimes
}

df = pd.DataFrame(data)

df.head()

"""# API

get data from intrernet using API (Star war API)
"""

import requests

# url => endpoint
url = "https://swapi.dev/api/people/1"

response = requests.get(url)
response.status_code

# response ที่ได้ออกมา คือ JSON format
response.json()

json_resp = response.json()

# get 10 characters (1-10)
import time
base_url = "https://swapi.dev/api/people/"

for i in range(10):
    url = base_url + str(i+1)
    response = requests.get(url)
    print(response.json()['name'])
    time.sleep(2) # ยิง 1 รอบ พัก 2 วิ ค่อยยิงต่อ

